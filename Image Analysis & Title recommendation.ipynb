{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc1d11ee-0f0c-4dec-9cb0-7d0110b89820",
   "metadata": {},
   "source": [
    "## Azure Vision Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12e2cb6e-a06e-4ad3-b56d-5bb2e975d158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'VISION_ENDPOINT': 'https://visiontext.cognitiveservices.azure.com/', 'VISION_KEY': '2WAJSYXSWaXnqDT1F4bELeUxfkCh8gBuTGHAfTAgAkShMsz04MOvJQQJ99AKACYeBjFXJ3w3AAAAACOGaC49', 'AZURE_LANGUAGE_ENDPOINT': 'https://visiontext.openai.azure.com/', 'AZURE_LANGUAGE_KEY': '2WAJSYXSWaXnqDT1F4bELeUxfkCh8gBuTGHAfTAgAkShMsz04MOvJQQJ99AKACYeBjFXJ3w3AAAAACOGaC49'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('credentials.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bebd6121-17b2-45c3-a965-e5f954c56bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Ignored the following yanked versions: 0.8.0a1, 0.8.0b0.dev33537970, 0.8.1b1, 0.9.0b1, 0.10.0b1, 0.11.1b1, 0.13.0b1, 0.15.1b1\n",
      "ERROR: Could not find a version that satisfies the requirement azure-ai-vision (from versions: none)\n",
      "ERROR: No matching distribution found for azure-ai-vision\n"
     ]
    }
   ],
   "source": [
    "!pip install azure-ai-vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2233e8ad-a649-4369-ae56-d1ce033acc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-ai-vision-imageanalysis==1.0.0b1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (1.0.0b1)\n",
      "Requirement already satisfied: isodate<1.0.0,>=0.6.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from azure-ai-vision-imageanalysis==1.0.0b1) (0.6.1)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.29.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from azure-ai-vision-imageanalysis==1.0.0b1) (1.29.6)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from azure-core<2.0.0,>=1.29.5->azure-ai-vision-imageanalysis==1.0.0b1) (4.2.0)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from azure-core<2.0.0,>=1.29.5->azure-ai-vision-imageanalysis==1.0.0b1) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from azure-core<2.0.0,>=1.29.5->azure-ai-vision-imageanalysis==1.0.0b1) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from azure-core<2.0.0,>=1.29.5->azure-ai-vision-imageanalysis==1.0.0b1) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->azure-core<2.0.0,>=1.29.5->azure-ai-vision-imageanalysis==1.0.0b1) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->azure-core<2.0.0,>=1.29.5->azure-ai-vision-imageanalysis==1.0.0b1) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->azure-core<2.0.0,>=1.29.5->azure-ai-vision-imageanalysis==1.0.0b1) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.29.5->azure-ai-vision-imageanalysis==1.0.0b1) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.29.5->azure-ai-vision-imageanalysis==1.0.0b1) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.29.5->azure-ai-vision-imageanalysis==1.0.0b1) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install azure-ai-vision-imageanalysis==1.0.0b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "056a19e0-a7de-4aaa-9dbe-5b6b8ca13b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.vision.imageanalysis import ImageAnalysisClient\n",
    "from azure.ai.vision.imageanalysis.models import VisualFeatures\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# Set the values of your computer vision endpoint and computer vision key\n",
    "# as environment variables:\n",
    "try:\n",
    "    endpoint = data[\"VISION_ENDPOINT\"]\n",
    "    key = data[\"VISION_KEY\"]\n",
    "except KeyError:\n",
    "    print(\"Missing environment variable 'VISION_ENDPOINT' or 'VISION_KEY'\")\n",
    "    print(\"Set them before running this sample.\")\n",
    "    exit()\n",
    "\n",
    "# Create an Image Analysis client for synchronous operations\n",
    "client = ImageAnalysisClient( endpoint=endpoint, credential=AzureKeyCredential(key)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92140b7f-4391-4782-987e-e2a35981abbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.vision.imageanalysis.aio import ImageAnalysisClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84d2b008-b347-446d-84ce-b656d9b98afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aiohttp in c:\\users\\dell\\anaconda3\\lib\\site-packages (3.10.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from aiohttp) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from aiohttp) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from aiohttp) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from aiohttp) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from aiohttp) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from aiohttp) (1.11.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from aiohttp) (4.0.3)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp) (3.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install aiohttp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c56b971f-45ea-4131-8cd1-03f10bce56e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image analysis results:\n",
      " Caption:\n",
      "   'a document with text on it', Confidence 0.6980\n"
     ]
    }
   ],
   "source": [
    "# Load image to analyze into a 'bytes' object\n",
    "with open(\"page_2.jpg\", \"rb\") as f:\n",
    "    image_data = f.read()\n",
    "\n",
    "# Get a caption for the image. This will be a synchronously (blocking) call.\n",
    "result = client.analyze(\n",
    "    image_data=image_data,\n",
    "    visual_features=[VisualFeatures.CAPTION],\n",
    "    gender_neutral_caption=True,  # Optional (default is False)\n",
    ")\n",
    "\n",
    "# Print caption results to the console\n",
    "print(\"Image analysis results:\")\n",
    "print(\" Caption:\")\n",
    "if result.caption is not None:\n",
    "    print(f\"   '{result.caption.text}', Confidence {result.caption.confidence:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "844f1ece-6980-4248-bea7-990938694250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image analysis results:\n",
      " Caption:\n",
      "   'a person wearing a mask sitting at a table with a laptop', Confidence 0.8503\n"
     ]
    }
   ],
   "source": [
    "# Get a caption for the image. This will be a synchronously (blocking) call.\n",
    "result = client.analyze(\n",
    "    image_url=\"https://aka.ms/azsdk/image-analysis/sample.jpg\",\n",
    "    visual_features=[VisualFeatures.CAPTION],\n",
    "    gender_neutral_caption=True,  # Optional (default is False)\n",
    ")\n",
    "\n",
    "# Print caption results to the console\n",
    "print(\"Image analysis results:\")\n",
    "print(\" Caption:\")\n",
    "if result.caption is not None:\n",
    "    print(f\"   '{result.caption.text}', Confidence {result.caption.confidence:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74d49213-4edf-49e4-a222-ffb14cad25b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image analysis results:\n",
      " Read:\n",
      "   Line: 'Sample text', Bounding box [{'x': 721, 'y': 502}, {'x': 843, 'y': 502}, {'x': 843, 'y': 519}, {'x': 721, 'y': 519}]\n",
      "     Word: 'Sample', Bounding polygon [{'x': 722, 'y': 503}, {'x': 785, 'y': 503}, {'x': 785, 'y': 520}, {'x': 722, 'y': 520}], Confidence 0.9930\n",
      "     Word: 'text', Bounding polygon [{'x': 800, 'y': 503}, {'x': 842, 'y': 502}, {'x': 842, 'y': 519}, {'x': 800, 'y': 520}], Confidence 0.9890\n",
      "   Line: 'Hand writing', Bounding box [{'x': 720, 'y': 525}, {'x': 819, 'y': 526}, {'x': 819, 'y': 544}, {'x': 720, 'y': 543}]\n",
      "     Word: 'Hand', Bounding polygon [{'x': 721, 'y': 526}, {'x': 759, 'y': 526}, {'x': 759, 'y': 544}, {'x': 721, 'y': 543}], Confidence 0.9890\n",
      "     Word: 'writing', Bounding polygon [{'x': 765, 'y': 526}, {'x': 819, 'y': 527}, {'x': 819, 'y': 545}, {'x': 765, 'y': 544}], Confidence 0.9940\n",
      "   Line: '123 456', Bounding box [{'x': 721, 'y': 548}, {'x': 791, 'y': 548}, {'x': 791, 'y': 563}, {'x': 721, 'y': 564}]\n",
      "     Word: '123', Bounding polygon [{'x': 723, 'y': 548}, {'x': 750, 'y': 548}, {'x': 750, 'y': 564}, {'x': 723, 'y': 564}], Confidence 0.9940\n",
      "     Word: '456', Bounding polygon [{'x': 761, 'y': 548}, {'x': 788, 'y': 549}, {'x': 787, 'y': 564}, {'x': 760, 'y': 564}], Confidence 0.9990\n"
     ]
    }
   ],
   "source": [
    "# Load image to analyze into a 'bytes' object\n",
    "with open(\"sample.jpg\", \"rb\") as f:\n",
    "    image_data = f.read()\n",
    "\n",
    "# Extract text (OCR) from an image stream. This will be a synchronously (blocking) call.\n",
    "result = client.analyze(\n",
    "    image_data=image_data,\n",
    "    visual_features=[VisualFeatures.READ]\n",
    ")\n",
    "\n",
    "# Print text (OCR) analysis results to the console\n",
    "print(\"Image analysis results:\")\n",
    "print(\" Read:\")\n",
    "if result.read is not None:\n",
    "    for line in result.read.blocks[0].lines:\n",
    "        print(f\"   Line: '{line.text}', Bounding box {line.bounding_polygon}\")\n",
    "        for word in line.words:\n",
    "            print(f\"     Word: '{word.text}', Bounding polygon {word.bounding_polygon}, Confidence {word.confidence:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
